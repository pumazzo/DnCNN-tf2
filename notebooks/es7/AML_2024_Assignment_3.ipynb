{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pumazzo/DnCNN-tf2/blob/master/notebooks/es7/AML_2024_Assignment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Advanced ML for Physics- aa 2023/24#\n",
        "##Home Project #3##\n",
        "\n",
        "**Scope:** Utilize a Graph Neural Network (GNN) employing PointNet++ architecture for jet tagging, the task is graph classification.\n",
        "\n",
        "**Tasks:**\n",
        "Given the dataset described in the next cell:\n",
        "\n",
        "- Data Preparation:\n",
        "    - Load the dataset provided in the subsequent cell.\n",
        "    - Construct a graph representation from the point cloud data.\n",
        "    - Generate the adjacency matrix based on the distances between   points in the $(\\eta, \\phi)$ plane, utilizing either a distance threshold or a fixed number of neighbors. Note that the number of neighbors or the distance threshold is a hyperparameter of the network.\n",
        "\n",
        "    - For efficiency during training, consider limiting the number of particles per jet to fewer than 100 (e.g., a maximum of 30 nodes per graph).\n",
        "    - Visualize a subset of events for each class to gain insights.\n",
        "\n",
        "- Model Implementation:\n",
        "    - Develop a PointNet++ model to conduct graph classification.\n",
        "\n",
        "- Evaluation:\n",
        "    - Assess the performance over the test set.\n",
        "    - Present the results using a Receiver Operating Characteristic (ROC) curve and a confusion matrix.\n",
        "    - Your performance evaluation will not be based on the achieved level of performance. It is adviced to  comment on your notebook, providing justifications for the decisions made and insights into the results obtained. **Clarity in reporting the results is considered more significant than the actual performance achieved**.\n",
        "\n",
        "\n",
        "**NOTE:** when done, upload the notebook of the project on: [TOBEOPEN]"
      ],
      "metadata": {
        "id": "MEap_tAgynfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Physics context:** <p>\n",
        "At the extreme energies of the Large Hadron Collider, massive particles can be produced with such high Lorentz boost that their decays into hadrons (hadron jets) are collimated in such a way that the resulting particles overlap. Deducing whether the substructure of an observed jet is due to a single low-mass particle or to multiple decay objects of a high-mass particle is an important problem in LHC data analysis. Traditional approaches are based on high-level observables built from theoretical models of energy deposition in calorimeters and charged tracks parameters reconsrtcuted in the inner tracker, but the complexity of the data makes this task an excellent candidate for the application of deep learning tools. The jet constituents can be in fact represented either as 2D or 3D images,lending itself to the natural application of image classification techniques (CNN, ViT etc.), or as pointclouds/graphs, that can be classified with GNNs, or as sequences, that can be analysed by RNNs or Transformers.\n",
        "\n",
        "\n",
        "**Dataset:** <p>\n",
        "The dataset is the *JetDataset*: you can find a description in [this presentation](https://docs.google.com/presentation/d/1dHhPSFPlhy332SIJnmu5kwHRd0jvReKsr6ma0Cgnrac/edit?usp=sharing)\n"
      ],
      "metadata": {
        "id": "rhjIf_0zKo-w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZ-gRA17yj0o",
        "outputId": "07da5c82-21c8-4576-c59b-258f9d7548b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2.1+cu121\n",
            "0.17.1+cu121\n"
          ]
        }
      ],
      "source": [
        "#imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import h5py\n",
        "import glob\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset download\n",
        "# we'll clone a github repository from M. Pierini containing the dataset\n",
        "! git clone https://github.com/pierinim/tutorials.git\n",
        "! ls tutorials/Data/JetDataset/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLybPsA3K6mo",
        "outputId": "2b26681f-1152-48f1-80b0-022f5083a916"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tutorials'...\n",
            "remote: Enumerating objects: 707, done.\u001b[K\n",
            "remote: Counting objects: 100% (128/128), done.\u001b[K\n",
            "remote: Compressing objects: 100% (90/90), done.\u001b[K\n",
            "remote: Total 707 (delta 58), reused 105 (delta 35), pack-reused 579\u001b[K\n",
            "Receiving objects: 100% (707/707), 566.43 MiB | 17.72 MiB/s, done.\n",
            "Resolving deltas: 100% (260/260), done.\n",
            "Updating files: 100% (79/79), done.\n",
            "jetImage_7_100p_0_10000.h5\tjetImage_7_100p_40000_50000.h5\tjetImage_7_100p_70000_80000.h5\n",
            "jetImage_7_100p_10000_20000.h5\tjetImage_7_100p_50000_60000.h5\tjetImage_7_100p_80000_90000.h5\n",
            "jetImage_7_100p_30000_40000.h5\tjetImage_7_100p_60000_70000.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define device to use (cpu/gpu)\n",
        "if torch.cuda.is_available():\n",
        "  print('# of GPUs available: ', torch.cuda.device_count())\n",
        "  print('First GPU type: ',torch.cuda.get_device_name(0))\n",
        "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Computation device: {device}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRUVbrgYK-xt",
        "outputId": "49d7d744-7300-42fc-ea92-f64e34428037"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computation device: cpu\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Handling\n",
        "\n",
        "The dataset consists of a list of jets. For each jet, we have up to 100 particles (zero-padding is used in case a jet has less than 100 particles).\n",
        "\n",
        "For each particle, we have 16 features:\n",
        "\n",
        "* the four-momentum in cartesian coordinates $(p_x,p_y,p_z,E)$\n",
        "* the energy divided by the jet energy ($E_{rel}$)\n",
        "* the transverse momentum ($p_T$), i.e. the momentum projected on the plane transverse to proton beams\n",
        "* the momentum transverse to the jet direction ($p_{Trel}$)\n",
        "* the pseudorapidity ($\\eta$), a function of the polar angle (see https://en.wikipedia.org/wiki/Pseudorapidity)\n",
        "* the pseudorapidity relative to the jet direction ($\\eta_{rel}$)\n",
        "* the pseudorapidity relative to the jet direction ($\\eta_{rot}$) after a rotation is applied so that the jet image looks vertical\n",
        "* the azimuth angle ($\\phi$)\n",
        "* the azimuth angle relative to the jet direction ($\\phi_{rel}$)\n",
        "* the azimuth angle relative to the jet direction ($\\phi_{rot}$) after a rotation is applied so that the jet image looks vertical\n",
        "\n",
        "The ground truth is incorporated in a ['j_g', 'j_q', 'j_w', 'j_z', 'j_t] vector of boolean, taking the form:\n",
        "\n",
        "* $[1, 0, 0, 0, 0]$ for gluons\n",
        "* $[0, 1, 0, 0, 0]$ for quarks\n",
        "* $[0, 0, 1, 0, 0]$ for W bosons (with W  qq)\n",
        "* $[0, 0, 0, 1, 0]$ for Z bosons (with Z  qq)\n",
        "* $[0, 0, 0, 0, 1]$ for top quarks (with t  Wq  qqq)\n",
        "\n",
        "This is what is called 'one-hot' encoding of a discrete label (typical of ground truth for classification problems).\n",
        "\n",
        "Additional information on this dataset and data handling can be found [HERE](https://github.com/pierinim/tutorials/blob/master/GGI_Jan2021/Lecture1/Notebook1_ExploreDataset.ipynb)"
      ],
      "metadata": {
        "id": "NT65XPL5LEVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data is stored in hirearchical data format (h5), a file format desgined to store and maniuplate large size data structures\n",
        "# .h5 files can be accesses in python using the h5py library (https://docs.h5py.org/en/stable/)\n",
        "\n",
        "# read dataset (only 50k events to keep training time ~20' on google colab, better performance can be obtained adding the three commented files\n",
        "target = np.array([])\n",
        "p_data = np.array([])\n",
        "datafiles = [#'tutorials/Data/JetDataset/jetImage_7_100p_80000_90000.h5',\n",
        "             #'tutorials/Data/JetDataset/jetImage_7_100p_70000_80000.h5',\n",
        "             #'tutorials/Data/JetDataset/jetImage_7_100p_60000_70000.h5',\n",
        "             #'tutorials/Data/JetDataset/jetImage_7_100p_50000_60000.h5',\n",
        "             #'tutorials/Data/JetDataset/jetImage_7_100p_40000_50000.h5',\n",
        "             #'tutorials/Data/JetDataset/jetImage_7_100p_30000_40000.h5',\n",
        "             'tutorials/Data/JetDataset/jetImage_7_100p_10000_20000.h5',\n",
        "             'tutorials/Data/JetDataset/jetImage_7_100p_0_10000.h5']\n",
        "\n",
        "\n",
        "# let's print what is contained in one of the files:\n",
        "f = h5py.File(datafiles[0])\n",
        "print(list(f.keys()))\n",
        "f.close()\n",
        "\n",
        "# each file contains different numpy arrays, the ones we are interested in are:\n",
        "# \"jetConstituentsList\": containing for each jet, and for each jet constituent particle (up to 100 particles) the 16 features associated to the jet particle\n",
        "# \"jets\": containing for each jet several (59) global features of the jet, we are here interested in the elements from -6:-1 that provide a onehot encoding of the jet-type label ['j_g', 'j_q', 'j_w', 'j_z', 'j_t]\n",
        "\n",
        "\n",
        "#loop over the files and concatenate the content to the p_adat and target arrays\n",
        "for fileIN in datafiles:\n",
        "    print(\"Appending %s\" %fileIN)\n",
        "    f = h5py.File(fileIN) #read the h5 file\n",
        "    data = np.array(f.get(\"jetConstituentList\")) #jet constituents\n",
        "    targ = np.array(f.get('jets')[0:,-6:-1])  #select ['j_g', 'j_q', 'j_w', 'j_z', 'j_t] out of the 59 features presents in the container\n",
        "    p_data = np.concatenate([p_data, data], axis=0) if p_data.size else data\n",
        "    target = np.concatenate([target, targ], axis=0) if target.size else targ\n",
        "    del data, targ\n",
        "    f.close()\n",
        "\n",
        "print(target.shape, p_data.shape)\n",
        "\n",
        "p_featurenames = ['j1_px','j1_py','j1_pz','j1_e','j1_erel','j1_pt','j1_ptrel',\n",
        " 'j1_eta','j1_etarel','j1_etarot','j1_phi','j1_phirel','j1_phirot',\n",
        " 'j1_deltaR','j1_costheta','j1_costhetarel']\n",
        "\n",
        "print(p_featurenames)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAMb_5hCLNt6",
        "outputId": "0c254e55-2cb0-4266-eb29-8e606adc8da6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['jetConstituentList', 'jetFeatureNames', 'jetImage', 'jetImageECAL', 'jetImageHCAL', 'jets', 'particleFeatureNames']\n",
            "Appending tutorials/Data/JetDataset/jetImage_7_100p_50000_60000.h5\n",
            "Appending tutorials/Data/JetDataset/jetImage_7_100p_40000_50000.h5\n",
            "Appending tutorials/Data/JetDataset/jetImage_7_100p_30000_40000.h5\n",
            "Appending tutorials/Data/JetDataset/jetImage_7_100p_10000_20000.h5\n",
            "Appending tutorials/Data/JetDataset/jetImage_7_100p_0_10000.h5\n",
            "(50000, 5) (50000, 100, 16)\n",
            "['j1_px', 'j1_py', 'j1_pz', 'j1_e', 'j1_erel', 'j1_pt', 'j1_ptrel', 'j1_eta', 'j1_etarel', 'j1_etarot', 'j1_phi', 'j1_phirel', 'j1_phirot', 'j1_deltaR', 'j1_costheta', 'j1_costhetarel']\n"
          ]
        }
      ]
    }
  ]
}